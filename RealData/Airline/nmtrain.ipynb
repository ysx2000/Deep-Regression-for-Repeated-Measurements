{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch             # torch基础库\n",
    "import torch.nn as nn    # torch神经网络库\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from early_stopping import EarlyStopping\n",
    "import os, gc\n",
    "import random \n",
    "import subprocess\n",
    "import rpy2.robjects as robjects\n",
    "\n",
    "\n",
    "\n",
    "def get_gpu_memory(device_id):\n",
    "    \"\"\"\n",
    "    Retrieve the memory usage of a specific GPU.\n",
    "\n",
    "    Parameters:\n",
    "    device_id: ID of the GPU device to query.\n",
    "\n",
    "    Returns: A tuple (memory_used, memory_total) in MB, or (None, None) if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        output = subprocess.check_output([\"nvidia-smi\", \"--id={}\".format(device_id), \"--query-gpu=memory.used,memory.total\", \"--format=csv,nounits,noheader\"])\n",
    "        memory_used, memory_total = map(int, output.decode(\"utf-8\").strip().split(\"\\n\")[0].split(\",\"))\n",
    "        return memory_used, memory_total\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None, None\n",
    "\n",
    "def get_free_gpu():\n",
    "    \"\"\"\n",
    "    Find the GPU with the most available memory and return its device ID.\n",
    "    \n",
    "    Returns:\n",
    "    torch.device or None: The device with the most free memory if available, otherwise None.\n",
    "    \"\"\"\n",
    "    device_ids = list(range(torch.cuda.device_count()))\n",
    "    memory_usages = []\n",
    "    for device_id in device_ids:\n",
    "        memory_used, memory_total = get_gpu_memory(device_id)\n",
    "        if memory_used is not None and memory_total is not None:\n",
    "            memory_free = memory_total - memory_used\n",
    "            memory_usages.append((device_id, memory_free))\n",
    "        print(memory_total,memory_usages)\n",
    "    if len(memory_usages) > 0:\n",
    "        best_device_id = sorted(memory_usages, key=lambda x: x[1])[len(device_ids)-1][0]\n",
    "        device = torch.device(f\"cuda:{best_device_id}\")\n",
    "        return device\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "class Args:\n",
    "    \"\"\"\n",
    "    A class to store tuning parameters for model training.\n",
    "    \n",
    "    Attributes:\n",
    "    batch_size: batch size.\n",
    "    lr: Learning rate for the optimizer.\n",
    "    nepoch: Total number of epochs for training.\n",
    "    patience: Number of epochs to wait for improvement before stopping early.\n",
    "    wide: Width of the model, representing the number of units in each layer.\n",
    "    depth: Depth of the model, representing the number of layers.\n",
    "    n_train (int): Sample size.\n",
    "    m_train (int): Sampling frequency.\n",
    "    biaoji (str): A unique identifier to aovid confusion.\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size=10, lr =0.001, nepoch = 200, patience = 10, wide = 100, depth = 5, n_train=1, m_train=1) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.nepoch = nepoch \n",
    "        self.patience = patience \n",
    "        self.wide = wide \n",
    "        self.depth = depth \n",
    "        self.biaoji = \"wide\" + str(wide) + \"depth\" + str(depth) + \"n\" + str(n_train) + \"m\" + str(m_train)\n",
    "        self.n_train = n_train\n",
    "        self.m_train = m_train\n",
    "\n",
    "\n",
    "class EarlyStopping():\n",
    "    \"\"\"\n",
    "    Early stopping utility to halt training when validation loss does not improve.\n",
    "    \n",
    "    Attributes:\n",
    "    save_path: Path where model checkpoints are saved.\n",
    "    patience: Number of epochs to wait for improvement before stopping.\n",
    "    verbose: If True, prints validation loss improvements.\n",
    "    delta: Minimum change in validation loss to qualify as an improvement.\n",
    "    counter: Tracks epochs without improvement.\n",
    "    best_score: Best score achieved on validation loss (initialized to None).\n",
    "    early_stop: Flag to indicate if training should be stopped.\n",
    "    val_loss_min: Tracks the minimum validation loss seen so far.\n",
    "    \"\"\"\n",
    "    def __init__(self, save_path, args, verbose=False, delta=0):\n",
    "        self.save_path = save_path \n",
    "        self.patience = args.patience \n",
    "        self.verbose = verbose \n",
    "        self.counter = 0 \n",
    "        self.best_score = None \n",
    "        self.early_stop = False \n",
    "        self.val_loss_min = np.Inf \n",
    "        self.delta = delta \n",
    "\n",
    "    def __call__(self, model, train_loss, valid_loss, args, seed):\n",
    "\n",
    "        score = -valid_loss \n",
    "\n",
    "        if self.best_score is None: \n",
    "            self.best_score = score \n",
    "            self.save_checkpoint(model, train_loss, valid_loss, args, seed) \n",
    "        elif score < self.best_score + self.delta: \n",
    "            self.counter += 1 \n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}') \n",
    "            if self.counter >= self.patience: \n",
    "                self.early_stop = True \n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model, train_loss, valid_loss,  args, seed)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, model, train_loss, valid_loss,  args, seed):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...') \n",
    "        torch.save(model, os.path.join(self.save_path, 'best' + str(seed) + args.biaoji +'network.pth') )\t\n",
    "        torch.save(train_loss, os.path.join(self.save_path, 'best'+ str(seed) + args.biaoji +'train_loss.pth')) \n",
    "        torch.save(valid_loss, os.path.join(self.save_path, 'best'+ str(seed) + args.biaoji +'valid_loss.pth')) \n",
    "\n",
    "        self.val_loss_min = valid_loss\n",
    "    \n",
    "\n",
    "\n",
    "class Dataset_repeatedmeasurement(Dataset): \n",
    "    \"\"\"\n",
    "    A custom dataset class for handling repeated measurement data.\n",
    "    \n",
    "    Attributes:\n",
    "    x: Input data of features.\n",
    "    y: Target labels corresponding to the input data.\n",
    "    \n",
    "    Methods:\n",
    "    __len__: Returns the total number of samples in the dataset.\n",
    "    __getitem__: Retrieves a single sample, returning a dictionary with 'x' and 'y' keys.\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y) -> None: \n",
    "        \"\"\"\n",
    "        Initialize the dataset with input data and corresponding labels.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.x = x \n",
    "        self.y = y \n",
    "\n",
    "    def __len__(self) -> int: \n",
    "        \"\"\"\n",
    "        Return the number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.x) \n",
    "    \n",
    "    def __getitem__(self, index): \n",
    "        \"\"\"\n",
    "        Retrieve a sample from the dataset at the specified index.\n",
    "        \"\"\"\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "\n",
    "\n",
    "class happynet(nn.Module):\n",
    "    \"\"\"\n",
    "    A flexible neural network with a customizable depth.\n",
    "    \n",
    "    Parameters:\n",
    "    n_feature: Dimension of input.\n",
    "    n_hidden: Number of units in each hidden layer.\n",
    "    n_output: Number of output units.\n",
    "    n_layer: the number of layers (supports 3 to 10 layers). \n",
    "             (n_layer-1) hidden layers\n",
    "    \n",
    "    Methods:\n",
    "    forward(x): Forward pass through the network.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_feature, n_hidden, n_output, n_layer): \n",
    "        super().__init__()\n",
    "        if n_layer == 3: \n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(n_feature, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_output), \n",
    "            )\n",
    "        elif n_layer == 2: \n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(n_feature, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_output), \n",
    "            )    \n",
    "        elif n_layer == 4: \n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(n_feature, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_output), \n",
    "            )\n",
    "        elif n_layer == 5: \n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(n_feature, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),  \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_output),\n",
    "            )\n",
    "        elif n_layer == 6: \n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(n_feature, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),  \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_output),\n",
    "            )\n",
    "        elif n_layer == 7: \n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(n_feature, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),  \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_output),\n",
    "            )\n",
    "        elif n_layer == 8: \n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(n_feature, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),  \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_output),\n",
    "            )\n",
    "        elif n_layer == 9: \n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(n_feature, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),  \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_output),\n",
    "            )\n",
    "        elif n_layer == 10: \n",
    "            self.net = nn.Sequential(\n",
    "                nn.Linear(n_feature, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),  \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden), \n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(n_hidden, n_output),\n",
    "            )\n",
    "        else: \n",
    "            print(\"Error! the depth is not in 3-10\")\n",
    "    \n",
    "    #定义前向运算\n",
    "    def forward(self, x):\n",
    "        k = self.net(x)\n",
    "        return k\n",
    "\n",
    "\n",
    "\n",
    "def GPUstrain2(x, y, x_valid, y_valid, args,seed,nocuda):  \n",
    "    \"\"\"\n",
    "    Train a neural network on GPU or CPU based on the given configuration, using early stopping.\n",
    "    \n",
    "    Parameters:\n",
    "    x: Training input data.\n",
    "    y: Training target data.\n",
    "    x_valid: Validation input data.\n",
    "    y_valid: Validation target data.\n",
    "    x_test: Test input data.\n",
    "    y_test: Test target data.\n",
    "    args: Arguments object containing hyperparameters.\n",
    "    seed: Seed and identifier.\n",
    "    nocuda (int): Flag to select device; options include specific GPU IDs, CPU, or auto-selection.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (trained network, list of training losses, list of validation losses, list of test errors)\n",
    "    \"\"\"\n",
    "\n",
    "    x_dim = 1 \n",
    "\n",
    "    if nocuda == 0:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    if nocuda == 1:\n",
    "        device = torch.device(\"cuda:1\")\n",
    "    if nocuda == 100:\n",
    "        device = get_free_gpu()\n",
    "    if nocuda == -1:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "    net = happynet(n_feature=x_dim, n_hidden=args.wide, n_output=1, n_layer=args.depth).to(device)\n",
    "    nepoch = args.nepoch\n",
    "    \n",
    "    optimizer=torch.optim.Adam(net.parameters(), lr=args.lr, betas=(0.90, 0.999), eps=1e-8, weight_decay=0., amsgrad=False,)  \n",
    "    loss_func=nn.MSELoss() \n",
    "    train_epochs_loss = [] \n",
    "    valid_epochs_loss = [] \n",
    "    x = x.reshape(-1,x_dim)\n",
    "    y = y.reshape(-1)\n",
    "\n",
    "    x=torch.from_numpy(x).float().to(device)\n",
    "    y=torch.from_numpy(y).float().to(device)\n",
    "    x_valid=torch.from_numpy(x_valid).float().to(device) \n",
    "    y_valid=torch.from_numpy(y_valid).float().to(device) \n",
    "    train_dataset = Dataset_repeatedmeasurement(x,y)\n",
    "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "\n",
    "    save_path = \"./resultsv\" \n",
    "    early_stopping = EarlyStopping(save_path,args=args)\n",
    "\n",
    "    for epoch in range(nepoch): \n",
    "        net.train()\n",
    "        train_epoch_loss = []\n",
    "\n",
    "        # =========================train=========================\n",
    "        for idx, traindata in enumerate(train_dataloader):\n",
    "            x_train, y_train = traindata\n",
    "            x_train=torch.Tensor(x_train).float().view(-1,1,x_dim)\n",
    "            y_train=torch.Tensor(y_train).float()\n",
    "            outputs=net(x_train) \n",
    "\n",
    "            loss=loss_func(outputs.view(-1),y_train.view(-1).float())\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            loss.backward()  \n",
    "            optimizer.step()  \n",
    "            \n",
    "            train_epoch_loss.append(loss.item())\n",
    "\n",
    "        del outputs, loss\n",
    "\n",
    "        train_epochs_loss.append(np.average(train_epoch_loss))\n",
    "\n",
    "        # =========================valid=========================\n",
    "        with torch.no_grad():\n",
    "            net.eval() \n",
    "\n",
    "            valid_predict=net(x_valid.view(-1,1,x_dim))\n",
    "            valid_y_pre=valid_predict.view(-1).detach()\n",
    "            valid_y_pre=torch.Tensor(valid_y_pre).float()\n",
    "            loss_valid=loss_func(valid_y_pre, y_valid.view(-1).float())\n",
    "            valid_epochs_loss.append(loss_valid.item())\n",
    "\n",
    "\n",
    "\n",
    "        print(\"epoch = {}, training loss = {}, validation loss = {}\".format(epoch, np.average(train_epoch_loss), loss_valid)) \n",
    "\n",
    "\n",
    "        if epoch > 10 or args.n_train*args.m_train < 200:\n",
    "            early_stopping(net, np.average(train_epoch_loss), loss_valid, args,seed)\n",
    "            if early_stopping.early_stop: \n",
    "                print(\"Early stopping\")\n",
    "                break  \n",
    "\n",
    "\n",
    "        del valid_predict, valid_y_pre, loss_valid \n",
    "    gc.collect()\n",
    "\n",
    "    return net, train_epochs_loss, valid_epochs_loss  \n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(12345) \n",
    "np.random.seed(12345) \n",
    "random.seed(12345) \n",
    "torch.cuda.manual_seed_all(12345) \n",
    "\n",
    "robjects.r['load'](\"./data/datahao/data2008.Rdata\") \n",
    "\n",
    "nnn_vec = [100,500,1000,5000]\n",
    "mma = [1,5,10,20,30,25,50]\n",
    "res = np.zeros(shape=(len(nnn_vec), len(mma), 3))\n",
    "\n",
    "for nnnind in range(len(nnn_vec)):\n",
    "    nnn = nnn_vec[nnnind]\n",
    "    n_train = nnn\n",
    "    n_valid = math.ceil(nnn * 0.25)\n",
    "    torch.manual_seed(123456) \n",
    "    np.random.seed(123456) \n",
    "    random.seed(123456) \n",
    "    torch.cuda.manual_seed_all(123456) \n",
    "    randind = list(range(len(robjects.r['data'][0])))\n",
    "    random.shuffle(randind)\n",
    "    train_ind = [randind[i] for i in range(0, math.ceil(len(robjects.r['data'][0]) * 0.8 ))]\n",
    "    valid_ind = [randind[i] for i in range(math.ceil(len(robjects.r['data'][0]) * 0.8 ), len(robjects.r['data'][0]))]\n",
    "    train_ind = [train_ind[i] for i in range(n_train)]\n",
    "    valid_ind = [valid_ind[i] for i in range(n_valid)]\n",
    "\n",
    "    for mind in range(len(mma)):\n",
    "        m = mma[mind]\n",
    "        m_train = m\n",
    "        m_valid = m\n",
    "        y_train = np.array([]) \n",
    "        pp_train = np.array([]) \n",
    "        for i in train_ind:\n",
    "            random.seed(123*i) \n",
    "            train_ind_m = list(range(50))\n",
    "            random.shuffle(train_ind_m)\n",
    "            for jj in range(m):\n",
    "                j = train_ind_m[jj]\n",
    "                y_train = np.append(y_train, robjects.r['data'][1][i][j])\n",
    "                pp_train = np.append(pp_train, robjects.r['data'][0][i][j])\n",
    "                y_train = y_train.reshape(-1,1)\n",
    "                pp_train = pp_train.reshape(-1,1)\n",
    "\n",
    "        y_valid = np.array([]) \n",
    "        pp_valid = np.array([]) \n",
    "        for i in valid_ind:\n",
    "            random.seed(123*i*6) \n",
    "            train_ind_m = list(range(50))\n",
    "            random.shuffle(train_ind_m)\n",
    "            for jj in range(m):\n",
    "                j = train_ind_m[jj]\n",
    "                y_valid = np.append(y_valid, robjects.r['data'][1][i][j])\n",
    "                pp_valid = np.append(pp_valid, robjects.r['data'][0][i][j])\n",
    "                y_valid = y_valid.reshape(-1,1)\n",
    "                pp_valid = pp_valid.reshape(-1,1)\n",
    "\n",
    "        if n_train*m_train < 128:\n",
    "            batch_size= min(n_train*m_train, 32)\n",
    "            lr = 0.0005\n",
    "        elif n_train*m_train < 1024:\n",
    "            batch_size= 64\n",
    "            lr = 0.0005\n",
    "        elif n_train*m_train < 4096:\n",
    "            batch_size= 128\n",
    "            lr = 0.001\n",
    "        elif n_train*m_train < 8192:\n",
    "            batch_size= 256\n",
    "            lr = 0.001\n",
    "        elif n_train*m_train < 16384:\n",
    "            batch_size= 512\n",
    "            lr = 0.002\n",
    "        else:\n",
    "            batch_size= 1024\n",
    "            lr = 0.002\n",
    "        nocuda = 0\n",
    "        trun = 30\n",
    "        torch.manual_seed(123) \n",
    "        np.random.seed(123) \n",
    "        random.seed(123) \n",
    "        torch.cuda.manual_seed_all(123) \n",
    "\n",
    "        args = Args(lr=lr, wide=50, depth = 2, batch_size= batch_size, n_train=n_train, m_train=m_train)\n",
    "        GPUstrain2(x=pp_train,y=y_train,x_valid = pp_valid,y_valid=y_valid, args=args,seed = 123, nocuda = nocuda)\n",
    "\n",
    "        a = torch.load('./resultsv/best'+ str(123) + args.biaoji +'train_loss.pth')\n",
    "        b = torch.load('./resultsv/best'+ str(123) + args.biaoji +'valid_loss.pth')\n",
    "        net0 = torch.load('./resultsv/best'+ str(123) + args.biaoji +'network.pth')\n",
    "        a = np.expand_dims(a , 0)\n",
    "        b = np.expand_dims(b.cpu(), 0)\n",
    "        c0 = np.r_[a,b,0]\n",
    "\n",
    "        args = Args(lr=lr, wide=100, depth = 3, batch_size= batch_size, n_train=n_train, m_train=m_train)\n",
    "        GPUstrain2(x=pp_train,y=y_train,x_valid = pp_valid,y_valid=y_valid, args=args,seed = 123, nocuda = nocuda)\n",
    "        a = torch.load('./resultsv/best'+ str(123) + args.biaoji +'train_loss.pth')\n",
    "        b = torch.load('./resultsv/best'+ str(123) + args.biaoji +'valid_loss.pth')\n",
    "        net1 = torch.load('./resultsv/best'+ str(123) + args.biaoji +'network.pth')\n",
    "        a = np.expand_dims(a , 0)\n",
    "        b = np.expand_dims(b.cpu(), 0)\n",
    "        c1 = np.r_[a,b,1]\n",
    "\n",
    "\n",
    "        args = Args(lr=lr, wide=200, depth = 4, batch_size= batch_size, n_train=n_train, m_train=m_train)\n",
    "        GPUstrain2(x=pp_train,y=y_train,x_valid = pp_valid,y_valid=y_valid, args=args,seed = 123, nocuda = nocuda)\n",
    "        a = torch.load('./resultsv/best'+ str(123) + args.biaoji +'train_loss.pth')\n",
    "        b = torch.load('./resultsv/best'+ str(123) + args.biaoji +'valid_loss.pth')\n",
    "        net2 = torch.load('./resultsv/best'+ str(123) + args.biaoji +'network.pth')\n",
    "        a = np.expand_dims(a , 0)\n",
    "        b = np.expand_dims(b.cpu(), 0)\n",
    "        c2 = np.r_[a,b,2]\n",
    "\n",
    "        args = Args(lr=lr, wide=400, depth = 5, batch_size= batch_size, n_train=n_train, m_train=m_train)\n",
    "        GPUstrain2(x=pp_train,y=y_train,x_valid = pp_valid,y_valid=y_valid, args=args,seed = 123, nocuda = nocuda)\n",
    "        a = torch.load('./resultsv/best'+ str(123) + args.biaoji +'train_loss.pth')\n",
    "        b = torch.load('./resultsv/best'+ str(123) + args.biaoji +'valid_loss.pth')\n",
    "        net3 = torch.load('./resultsv/best'+ str(123) + args.biaoji +'network.pth')\n",
    "        a = np.expand_dims(a , 0)\n",
    "        b = np.expand_dims(b.cpu(), 0)\n",
    "        c3 = np.r_[a,b,3]\n",
    "\n",
    "        args = Args(lr=lr, wide=600, depth = 6, batch_size= batch_size, n_train=n_train, m_train=m_train)\n",
    "        GPUstrain2(x=pp_train,y=y_train,x_valid = pp_valid,y_valid=y_valid, args=args,seed = 123, nocuda = nocuda)\n",
    "        a = torch.load('./resultsv/best'+ str(123) + args.biaoji +'train_loss.pth')\n",
    "        b = torch.load('./resultsv/best'+ str(123) + args.biaoji +'valid_loss.pth')\n",
    "        net4 = torch.load('./resultsv/best'+ str(123) + args.biaoji +'network.pth')\n",
    "        a = np.expand_dims(a , 0)\n",
    "        b = np.expand_dims(b.cpu(), 0)\n",
    "        c4 = np.r_[a,b,4]\n",
    "        \n",
    "        args = Args(lr=lr, wide=800, depth = 6, batch_size= batch_size, n_train=n_train, m_train=m_train)\n",
    "        GPUstrain2(x=pp_train,y=y_train,x_valid = pp_valid,y_valid=y_valid, args=args,seed = 123, nocuda = nocuda)\n",
    "        a = torch.load('./resultsv/best'+ str(123) + args.biaoji +'train_loss.pth')\n",
    "        b = torch.load('./resultsv/best'+ str(123) + args.biaoji +'valid_loss.pth')\n",
    "        net5 = torch.load('./resultsv/best'+ str(123) + args.biaoji +'network.pth')\n",
    "        a = np.expand_dims(a , 0)\n",
    "        b = np.expand_dims(b.cpu(), 0)\n",
    "        c5 = np.r_[a,b,5]\n",
    "\n",
    "        p = np.r_[np.expand_dims(c0, 0),np.expand_dims(c1, 0),np.expand_dims(c2, 0),np.expand_dims(c3, 0),np.expand_dims(c4, 0),np.expand_dims(c5, 0)]\n",
    "        ind = np.argmin(p[:,1])\n",
    "        res[nnnind,mind,:]=p[ind]\n",
    "        torch.save( eval(\"net\"+str(ind)) , os.path.join(\"./bestnet/\", 'best' + str(nnn) +\"m\"+ str(m) +'net.pth') )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
